#V_LORA_R=(8 16 32)
#V_LORA_ALPHA=(16 32 64)
#V_LORA_DROPOUT=(0.1 0.2 0.3)
#V_NUM_TRAIN_EPOCHS=(2 3 4)
#V_MAX_GRAD_NORM=(1.0 1.0 1.0)
#V_LEARNING_RATE=(2e-5 2e-4 3e-4)
#V_WEIGHT_DECAY=(.01 .005 .001)
#V_WARMUP_RATIO=(0.1 0.2 0.3)
#V_MAX_SEQ_LENGTH=(1024 2048 8192)
V_LORA_R=(16 16 16 16 16 16)
V_LORA_ALPHA=(32 32 32 32 32 32)
V_LORA_DROPOUT=(0.2 0.2 0.2 0.2 0.2 0.2)
V_NUM_TRAIN_EPOCHS=(3 3 3 3 3 3)
V_MAX_GRAD_NORM=(1.0 1.0 1.0 1.0 1.0 1.0)
V_LEARNING_RATE=(2e-4 2e-4 2e-4 2e-4 2e-4 2e-4)
V_WEIGHT_DECAY=(.005 .005 .005 .005 .005 .005)
V_WARMUP_RATIO=(0.2 0.2 0.2 0.2 0.2 0.2)
V_MAX_SEQ_LENGTH=(2048 2048 2048 2048 2048 2048)
V_TRAIN_BATCH_SIZE=(8 8 16 16 24 24)
V_GRADIENT_ACCUMULATION_STEPS=(1 2 1 2 1 2)
# Set values to override trigger
#HP_IMAGE_URL=us-docker.pkg.dev/gkebatchexpce3c8dcb/llm/finetune:llama3
#HP_EXPERIMENT=llama3
#HP_MODEL_NAME=meta-llama/Meta-Llama-3-70B
#HP_MODEL_BUCKET=kr-finetune
#HP_MODEL_PATH=model-data/llama3-a100/experiment
#HP_TRAINING_DATASET_BUCKET=kh-finetune-ds
#HP_TRAINING_DATASET_PATH=dataset/output-abc12311